<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Credible Intervals versus Confidence Intervals | Svanik Sharma&#39;s Website</title>
<meta name="keywords" content="">
<meta name="description" content="Suppose you have data $X_i | \mu, \sigma^2 \sim N(\mu, \sigma^2)$, for $i = 1, &hellip;, n$, i.e, $n$ normally distributed data points with mean $\mu$ and variance $\sigma^2$ (or standard deviation $\sigma$). Assume you don&rsquo;t know $\sigma^2$, which is usually the case anyway. You could estimate $\mu \approx \bar{X}$ and call it a day, but you probably want some measure of uncertainty, i.e, an interval estimate.
Note: Throughout this article, I use the convention that uppercase variables are random variables and lowercase variables are fixed (observed) quantities.">
<meta name="author" content="">
<link rel="canonical" href="https://svaniksharma.github.io/posts/2024-07-16-credible-intervals-versus-confidence-intervals/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.b609c58d5c11bb90b1a54e04005d74ad1ddf22165eb79f5533967e57df9c3b50.css" integrity="sha256-tgnFjVwRu5CxpU4EAF10rR3fIhZet59VM5Z&#43;V9&#43;cO1A=" rel="preload stylesheet" as="style">
<link rel="icon" href="https://svaniksharma.github.io/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://svaniksharma.github.io/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://svaniksharma.github.io/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://svaniksharma.github.io/apple-touch-icon.png">
<link rel="mask-icon" href="https://svaniksharma.github.io/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="https://svaniksharma.github.io/posts/2024-07-16-credible-intervals-versus-confidence-intervals/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript>
  <script type="text/javascript">
  MathJax = {
    tex: {
      displayMath: [['$$', '$$'], ['\\[', '\\]']],
      inlineMath: [['$', '$'], ['\\(', '\\)']],
    },
  };
</script>
<script
    async
    id="MathJax-script"
    src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"
    integrity="sha384-+BSz3oj3ILMYvOBr16U9i0H4RZRmGyQQ+1q9eqr8T3skmAFrJk8GmgwgqlCZdNSo"
    crossorigin="anonymous"
    referrerpolicy="no-referrer"
    type="text/javascript"></script>



  

<meta property="og:title" content="Credible Intervals versus Confidence Intervals" />
<meta property="og:description" content="Suppose you have data $X_i | \mu, \sigma^2 \sim N(\mu, \sigma^2)$, for $i = 1, &hellip;, n$, i.e, $n$ normally distributed data points with mean $\mu$ and variance $\sigma^2$ (or standard deviation $\sigma$). Assume you don&rsquo;t know $\sigma^2$, which is usually the case anyway. You could estimate $\mu \approx \bar{X}$ and call it a day, but you probably want some measure of uncertainty, i.e, an interval estimate.
Note: Throughout this article, I use the convention that uppercase variables are random variables and lowercase variables are fixed (observed) quantities." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://svaniksharma.github.io/posts/2024-07-16-credible-intervals-versus-confidence-intervals/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2024-07-16T07:07:07+01:00" />
<meta property="article:modified_time" content="2024-07-16T07:07:07+01:00" />

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Credible Intervals versus Confidence Intervals"/>
<meta name="twitter:description" content="Suppose you have data $X_i | \mu, \sigma^2 \sim N(\mu, \sigma^2)$, for $i = 1, &hellip;, n$, i.e, $n$ normally distributed data points with mean $\mu$ and variance $\sigma^2$ (or standard deviation $\sigma$). Assume you don&rsquo;t know $\sigma^2$, which is usually the case anyway. You could estimate $\mu \approx \bar{X}$ and call it a day, but you probably want some measure of uncertainty, i.e, an interval estimate.
Note: Throughout this article, I use the convention that uppercase variables are random variables and lowercase variables are fixed (observed) quantities."/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Posts",
      "item": "https://svaniksharma.github.io/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Credible Intervals versus Confidence Intervals",
      "item": "https://svaniksharma.github.io/posts/2024-07-16-credible-intervals-versus-confidence-intervals/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Credible Intervals versus Confidence Intervals",
  "name": "Credible Intervals versus Confidence Intervals",
  "description": "Suppose you have data $X_i | \\mu, \\sigma^2 \\sim N(\\mu, \\sigma^2)$, for $i = 1, \u0026hellip;, n$, i.e, $n$ normally distributed data points with mean $\\mu$ and variance $\\sigma^2$ (or standard deviation $\\sigma$). Assume you don\u0026rsquo;t know $\\sigma^2$, which is usually the case anyway. You could estimate $\\mu \\approx \\bar{X}$ and call it a day, but you probably want some measure of uncertainty, i.e, an interval estimate.\nNote: Throughout this article, I use the convention that uppercase variables are random variables and lowercase variables are fixed (observed) quantities.",
  "keywords": [
    
  ],
  "articleBody": "Suppose you have data $X_i | \\mu, \\sigma^2 \\sim N(\\mu, \\sigma^2)$, for $i = 1, …, n$, i.e, $n$ normally distributed data points with mean $\\mu$ and variance $\\sigma^2$ (or standard deviation $\\sigma$). Assume you don’t know $\\sigma^2$, which is usually the case anyway. You could estimate $\\mu \\approx \\bar{X}$ and call it a day, but you probably want some measure of uncertainty, i.e, an interval estimate.\nNote: Throughout this article, I use the convention that uppercase variables are random variables and lowercase variables are fixed (observed) quantities.\nConfidence Intervals This is the typical approach taught in any statistics class. However, its interpretation is nuanced. We want to estimate $\\mu$ and find some interval in which it resides. That is, we want to find: $P(L \\le \\mu \\le U) = 1 - \\alpha$, where $\\alpha$ is usually some small quantity (e.g, 0.05). In this case, $L$ and $U$ are functions of the sample, which itself can be thought of as a random vector $\\boldsymbol{X} = (X_1, X_2, …, X_n)$. Then, taking $\\alpha = 0.05$, we want to calculate $P(L \\le \\mu \\le U) = 0.95$. This is a 95% confidence interval for $\\mu$. It tells us that the probability the interval $(L, U)$ will cover the true population mean $\\mu$ is 95%. That is, if we were to take 100 different samples and (somehow) calculate 100 intervals $(L, U)$, 95 of those intervals would contain the population mean but 5 of them would not. To make this more concrete, let’s calculate $L$ and $U$ for the sample we proposed in the beginning. We can use the fact that $$\\frac{\\bar{X} - \\mu}{\\frac{S}{\\sqrt{n}}}$$ is distributed as a $t$ distribution with $n-1$ degrees of freedom (which we denote $t_{n-1}$). Since the $t$-distribution is unimodal and symmetric, then the 97.5% and 2.5% quantiles are negatives of each other, i.e, $t_{n-1, \\alpha/2} = -t_{n-1, 1 - \\alpha/2}$, and:\n$$P(-t_{n-1, 1-\\alpha/2} \\le \\frac{\\bar{X} - \\mu}{\\frac{S}{\\sqrt{n}}} \\le t_{n-1, 1-\\alpha/2}) = 0.95$$\nHence,\n$$P(\\bar{X} - t_{n-1, 1-\\alpha/2} \\frac{S}{\\sqrt{n}} \\le \\mu \\le \\bar{X} + t_{n-1, 1-\\alpha/2} \\frac{S}{\\sqrt{n}}) = 0.95$$\nAnd so the confidence interval is given by $L = \\bar{X} - t_{n-1, 1-\\alpha/2} \\frac{S}{\\sqrt{n}}$ and $U = \\bar{X} + t_{n-1, 1-\\alpha/2} \\frac{S}{\\sqrt{n}}$.\nNotice that $L$ and $U$ are functions of $\\bar{X}$ and $S$, the sample mean and sample standard deviation. Hence, given any particular sample, we cannot know whether the interval we compute upon observing a sample does actually contain the true population mean.\nCredible Intervals This is a Bayesian approach. We first set up a joint prior distribution for $\\mu$ and $\\sigma$. One choice is to use a vague, noninformative prior distribution: $p(\\mu, \\sigma^2) \\propto \\sigma^{-2}$. The justification for this is hard to explicate succinctly here. See Gelman, particularly Section 2.5. There are many other reasonable choices, but I’ll use this one since I’ve given no particular information about $\\mu$ nor $\\sigma$. Also, though the prior is unnormalized (doesn’t integrate to 1), it can still be used since the posterior distribution is a probability density. Then, \\begin{align} p(\\mu, \\sigma^2 | \\boldsymbol{X}) \u0026\\propto p(\\boldsymbol{X} | \\mu, \\sigma^2) p(\\mu, \\sigma^2) \\\\ \u0026\\propto \\prod_{i=1}^n p(X_i | \\mu, \\sigma^2) p(\\mu, \\sigma^2) \\\\ \u0026\\propto \\prod_{i=1}^n N(X_i | \\mu, \\sigma^2) \\sigma^{-2} \\end{align}\nIf we integrate the last product with respect to $\\sigma^2$, then we get the distribution of $p(\\mu | \\boldsymbol{X})$. The integration step is slightly involved, but we get $\\mu | \\boldsymbol{X} \\sim t_{n-1}(\\bar{X}, \\frac{S^2}{n})$. This is called a posterior distribution. Now, to compute an interval estimate from $\\mu$, we will draw $S$ points from $\\mu | \\boldsymbol{X}$, then find the 2.5% and 97.5% sample quantiles and this will be our interval. Generally, we can express this as follows:\n$$P(l \\le \\mu \\le u | \\boldsymbol{X} = \\boldsymbol{x}) = \\int_{l(\\boldsymbol{x})}^{u(\\boldsymbol{x})} p(\\mu | \\boldsymbol{X} = \\boldsymbol{x}) d\\mu = 1 - \\alpha$$\nThis looks similar to the confidence interval. But the difference is that we are calculating the probability of $\\mu$ being covered by $(l, u)$ given an observed sample $\\boldsymbol{x}$. In other words, the probability $\\mu$ is contained in $(l, u)$ is 95%. This is less confusing than the confidence interval. Notice that there are two parts to this:\nTake our original $n$ normally-distributed sample points and compute the posterior probability distribution $\\mu | \\boldsymbol{X} \\sim t_{n-1}(\\bar{X}, \\frac{S^2}{n})$. Draw a random sample of $S$ points from the posterior $\\mu | \\boldsymbol{X}$, sort them, and use the 2.5% and 97.5% points to compute a posterior probability interval (credible interval). In other words, the original sample is used to specify the posterior distribution of $\\mu$ and then a new sample is simulated from the posterior distribution of $\\mu$ to compute the credible interval. This is why we can say there’s a 95% probability $\\mu$ lies in $(l, u)$: $l$ and $u$ are the result of a simulation, and they should contain 95% of the $S$ values between them. While the interpretation of credible intervals is easier to understand, there’s no guarantee they will produce the same results as a confidence interval. That being said, they usually get pretty close. For our purposes, they are almost the same:\npop_mean \u003c- 5.5 pop_sd \u003c- 3 n \u003c- 1000 set.seed(14151) sample \u003c- rnorm(n, mean = pop_mean, sd = pop_sd) # Confidence interval alpha \u003c- 0.05 sample_mean \u003c- mean(sample) sample_sd \u003c- sd(sample) crit \u003c- qt(alpha / 2, df = n - 1) upper \u003c- sample_mean + crit * sample_sd / sqrt(n) lower \u003c- sample_mean - crit * sample_sd / sqrt(n) print(paste0( upper, \", \", lower )) # Credible interval set.seed(14560) v = n - 1 simul \u003c- rt(1000, df = v) simul \u003c- simul / sqrt(v / (v - 2)) simul \u003c- simul * sample_sd / sqrt(n) simul \u003c- simul + sample_mean interval \u003c- sort(simul)[c(25, 976)] print(interval) For the confidence interval, we get $(5.229, 5.588)$. For the credible interval, we get $(5.232, 5.585)$. Also, in this artificial example, both intervals contain the true population mean.\nConclusion Ultimately, the distinction between the two is quite important. It’s easy to think a 90% confidence interval has a 90% probability of containing the mean, but this is incorrect:\nA $p$% confidence interval for a parameter means that if we were to generate 100 (or 1000 or 10000) samples and compute the interval using some procedure like the one described above, then $p$ (or $10p$ or $100p$) of those intervals would cover the true population parameter. A $p$% credible interval for a parameter means that there is a $p$% chance that the interval computed from the posterior distribution of the parameter will contain the true population parameter. References Bayesian Data Analysis 3rd Edition, Gelman Introduction to Mathematical Statistics, Hogg Computing a shifted and scaled t-distribution in R ",
  "wordCount" : "1103",
  "inLanguage": "en",
  "datePublished": "2024-07-16T07:07:07+01:00",
  "dateModified": "2024-07-16T07:07:07+01:00",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://svaniksharma.github.io/posts/2024-07-16-credible-intervals-versus-confidence-intervals/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Svanik Sharma's Website",
    "logo": {
      "@type": "ImageObject",
      "url": "https://svaniksharma.github.io/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://svaniksharma.github.io/" accesskey="h" title="Svanik Sharma&#39;s Website (Alt + H)">Svanik Sharma&#39;s Website</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
                <ul class="lang-switch"><li>|</li>
                </ul>
            </div>
        </div>
        <ul id="menu">
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    
    <h1 class="post-title entry-hint-parent">
      Credible Intervals versus Confidence Intervals
    </h1>
    <div class="post-meta"><span title='2024-07-16 07:07:07 +0100 +0100'>July 16, 2024</span>

</div>
  </header> 
  <div class="post-content"><p>Suppose you have data $X_i | \mu, \sigma^2 \sim N(\mu, \sigma^2)$, for $i = 1, &hellip;, n$, i.e, $n$ normally
distributed data points with mean $\mu$ and variance $\sigma^2$ (or standard deviation $\sigma$). Assume you
don&rsquo;t know $\sigma^2$, which is usually the case anyway.
You could estimate $\mu \approx \bar{X}$ and call it a day, but you probably want some measure of uncertainty, i.e, an interval estimate.</p>
<p><em>Note</em>: Throughout this article, I use the convention that uppercase variables are random variables and lowercase variables are fixed (observed)
quantities.</p>
<h2 id="confidence-intervals">Confidence Intervals<a hidden class="anchor" aria-hidden="true" href="#confidence-intervals">#</a></h2>
<p>This is the typical approach taught in any statistics class. However, its interpretation is nuanced.
We want to estimate $\mu$ and find some interval in which it resides. That is, we want to find:
$P(L \le \mu \le U) = 1 - \alpha$, where $\alpha$ is usually some small quantity (e.g, 0.05).
In this case, $L$ and $U$ are functions of the sample, which itself can be thought of as a random
vector $\boldsymbol{X} = (X_1, X_2, &hellip;, X_n)$.
Then, taking $\alpha = 0.05$, we want to calculate $P(L \le \mu \le U) = 0.95$. This is a <em>95% confidence interval</em>
for $\mu$. It tells us that the probability the interval $(L, U)$ will cover the true population mean $\mu$ is 95%.
That is, if we were to take 100 different samples and (somehow) calculate 100 intervals $(L, U)$, 95 of those intervals
would contain the population mean but 5 of them would <strong>not</strong>.
To make this more concrete, let&rsquo;s calculate $L$ and $U$ for the sample we proposed in the beginning. We can use the fact that
$$\frac{\bar{X} - \mu}{\frac{S}{\sqrt{n}}}$$
is distributed as a $t$ distribution with $n-1$ degrees of freedom (which we denote $t_{n-1}$).
Since the $t$-distribution is unimodal and symmetric, then the 97.5% and 2.5% quantiles are negatives of each other, i.e,
$t_{n-1, \alpha/2} = -t_{n-1, 1 - \alpha/2}$, and:</p>
<p>$$P(-t_{n-1, 1-\alpha/2} \le \frac{\bar{X} - \mu}{\frac{S}{\sqrt{n}}} \le t_{n-1, 1-\alpha/2}) = 0.95$$</p>
<p>Hence,</p>
<p>$$P(\bar{X} - t_{n-1, 1-\alpha/2} \frac{S}{\sqrt{n}} \le \mu \le \bar{X} + t_{n-1, 1-\alpha/2} \frac{S}{\sqrt{n}}) = 0.95$$</p>
<p>And so the confidence interval is given by $L = \bar{X} - t_{n-1, 1-\alpha/2} \frac{S}{\sqrt{n}}$ and $U = \bar{X} + t_{n-1, 1-\alpha/2} \frac{S}{\sqrt{n}}$.</p>
<p>Notice that $L$ and $U$ are functions of $\bar{X}$ and $S$, the sample mean and sample standard deviation. Hence, given any particular sample,
<strong>we cannot know whether the interval we compute upon observing a sample does actually contain the true population mean</strong>.</p>
<h2 id="credible-intervals">Credible Intervals<a hidden class="anchor" aria-hidden="true" href="#credible-intervals">#</a></h2>
<p>This is a Bayesian approach. We first set up a joint prior distribution for $\mu$ and $\sigma$. One choice is to use
a vague, <em>noninformative prior</em> distribution: $p(\mu, \sigma^2) \propto \sigma^{-2}$.
The justification for this is hard to explicate succinctly here. See <a href="http://www.stat.columbia.edu/~gelman/book/BDA3.pdf">Gelman</a>,
particularly Section 2.5. There are many other reasonable choices, but I&rsquo;ll use this one since I&rsquo;ve given no particular information
about $\mu$ nor $\sigma$. Also, though the prior is unnormalized (doesn&rsquo;t integrate to 1), it can still be used since the posterior distribution is a probability density.
Then,
\begin{align}
p(\mu, \sigma^2 | \boldsymbol{X})
&amp;\propto p(\boldsymbol{X} | \mu, \sigma^2) p(\mu, \sigma^2) \\
&amp;\propto \prod_{i=1}^n p(X_i | \mu, \sigma^2) p(\mu, \sigma^2) \\
&amp;\propto \prod_{i=1}^n N(X_i | \mu, \sigma^2) \sigma^{-2}
\end{align}</p>
<p>If we integrate the last product with respect to $\sigma^2$, then we get the distribution of $p(\mu | \boldsymbol{X})$.
The integration step is slightly involved, but we get $\mu | \boldsymbol{X} \sim t_{n-1}(\bar{X}, \frac{S^2}{n})$. This is
called a <em>posterior</em> distribution.
Now, to compute an interval estimate from $\mu$, we will draw $S$ points from $\mu | \boldsymbol{X}$, then find the 2.5%
and 97.5% sample quantiles and this will be our interval. Generally, we can express this as follows:</p>
<p>$$P(l \le \mu \le u | \boldsymbol{X} = \boldsymbol{x}) = \int_{l(\boldsymbol{x})}^{u(\boldsymbol{x})} p(\mu | \boldsymbol{X} = \boldsymbol{x}) d\mu = 1 - \alpha$$</p>
<p>This looks similar to the confidence interval. But the difference is that we are calculating the probability of $\mu$ being covered
by $(l, u)$ <strong>given</strong> an observed sample $\boldsymbol{x}$. In other words, the probability $\mu$ is contained in $(l, u)$ is 95%. This is
less confusing than the confidence interval. Notice that there are two parts to this:</p>
<ol>
<li>Take our original $n$ normally-distributed sample points and compute the posterior probability distribution $\mu | \boldsymbol{X} \sim t_{n-1}(\bar{X}, \frac{S^2}{n})$.</li>
<li>Draw a random sample of $S$ points from the posterior $\mu | \boldsymbol{X}$, sort them, and use the 2.5% and 97.5% points to compute a posterior probability interval (credible interval).
In other words, the original sample is used to specify the posterior distribution of $\mu$ and then a <em>new</em> sample is simulated from the posterior distribution of $\mu$ to compute the
credible interval. This is why we can say there&rsquo;s a 95% probability $\mu$ lies in $(l, u)$: $l$ and $u$ are the result of a simulation, and they should contain 95% of the $S$ values
between them.</li>
</ol>
<p>While the interpretation of credible intervals is easier to understand, there&rsquo;s no guarantee they will produce the same results as a confidence interval. That being said, they usually
get pretty close. For our purposes, they are almost the same:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-r" data-lang="r"><span style="display:flex;"><span>pop_mean <span style="color:#f92672">&lt;-</span> <span style="color:#ae81ff">5.5</span>
</span></span><span style="display:flex;"><span>pop_sd <span style="color:#f92672">&lt;-</span> <span style="color:#ae81ff">3</span>
</span></span><span style="display:flex;"><span>n <span style="color:#f92672">&lt;-</span> <span style="color:#ae81ff">1000</span>
</span></span><span style="display:flex;"><span><span style="color:#a6e22e">set.seed</span>(<span style="color:#ae81ff">14151</span>)
</span></span><span style="display:flex;"><span>sample <span style="color:#f92672">&lt;-</span> <span style="color:#a6e22e">rnorm</span>(n, mean <span style="color:#f92672">=</span> pop_mean, sd <span style="color:#f92672">=</span> pop_sd)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Confidence interval</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>alpha <span style="color:#f92672">&lt;-</span>  <span style="color:#ae81ff">0.05</span>
</span></span><span style="display:flex;"><span>sample_mean <span style="color:#f92672">&lt;-</span> <span style="color:#a6e22e">mean</span>(sample)
</span></span><span style="display:flex;"><span>sample_sd <span style="color:#f92672">&lt;-</span> <span style="color:#a6e22e">sd</span>(sample)
</span></span><span style="display:flex;"><span>crit <span style="color:#f92672">&lt;-</span> <span style="color:#a6e22e">qt</span>(alpha <span style="color:#f92672">/</span> <span style="color:#ae81ff">2</span>, df <span style="color:#f92672">=</span> n <span style="color:#f92672">-</span> <span style="color:#ae81ff">1</span>)
</span></span><span style="display:flex;"><span>upper <span style="color:#f92672">&lt;-</span> sample_mean <span style="color:#f92672">+</span> crit <span style="color:#f92672">*</span> sample_sd <span style="color:#f92672">/</span> <span style="color:#a6e22e">sqrt</span>(n)
</span></span><span style="display:flex;"><span>lower <span style="color:#f92672">&lt;-</span> sample_mean <span style="color:#f92672">-</span> crit <span style="color:#f92672">*</span> sample_sd <span style="color:#f92672">/</span> <span style="color:#a6e22e">sqrt</span>(n)
</span></span><span style="display:flex;"><span><span style="color:#a6e22e">print</span>(<span style="color:#a6e22e">paste0</span>(
</span></span><span style="display:flex;"><span>  upper,
</span></span><span style="display:flex;"><span>  <span style="color:#e6db74">&#34;, &#34;</span>,
</span></span><span style="display:flex;"><span>  lower
</span></span><span style="display:flex;"><span>))
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Credible interval</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#a6e22e">set.seed</span>(<span style="color:#ae81ff">14560</span>)
</span></span><span style="display:flex;"><span>v <span style="color:#f92672">=</span> n <span style="color:#f92672">-</span> <span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>simul <span style="color:#f92672">&lt;-</span> <span style="color:#a6e22e">rt</span>(<span style="color:#ae81ff">1000</span>, df <span style="color:#f92672">=</span> v)
</span></span><span style="display:flex;"><span>simul <span style="color:#f92672">&lt;-</span> simul <span style="color:#f92672">/</span> <span style="color:#a6e22e">sqrt</span>(v <span style="color:#f92672">/</span> (v <span style="color:#f92672">-</span> <span style="color:#ae81ff">2</span>))
</span></span><span style="display:flex;"><span>simul <span style="color:#f92672">&lt;-</span> simul <span style="color:#f92672">*</span> sample_sd <span style="color:#f92672">/</span> <span style="color:#a6e22e">sqrt</span>(n)
</span></span><span style="display:flex;"><span>simul <span style="color:#f92672">&lt;-</span> simul <span style="color:#f92672">+</span> sample_mean
</span></span><span style="display:flex;"><span>interval <span style="color:#f92672">&lt;-</span> <span style="color:#a6e22e">sort</span>(simul)<span style="color:#a6e22e">[c</span>(<span style="color:#ae81ff">25</span>, <span style="color:#ae81ff">976</span>)]
</span></span><span style="display:flex;"><span><span style="color:#a6e22e">print</span>(interval)
</span></span></code></pre></div><p>For the confidence interval, we get $(5.229, 5.588)$. For the credible interval, we get $(5.232, 5.585)$. Also, in this artificial example, both intervals contain the true population mean.</p>
<h2 id="conclusion">Conclusion<a hidden class="anchor" aria-hidden="true" href="#conclusion">#</a></h2>
<p>Ultimately, the distinction between the two is quite important. It&rsquo;s easy to think a 90% confidence interval has a 90% probability of containing the mean, but this is incorrect:</p>
<ol>
<li>A <strong>$p$% confidence interval</strong> for a parameter means that if we were to generate 100 (or 1000 or 10000) samples and compute the interval using some procedure like the one
described above, then $p$ (or $10p$ or $100p$) of those intervals would cover the true population parameter.</li>
<li>A <strong>$p$% credible interval</strong> for a parameter means that there is a $p$% chance that the interval computed from the posterior distribution of the parameter will contain
the true population parameter.</li>
</ol>
<h2 id="references">References<a hidden class="anchor" aria-hidden="true" href="#references">#</a></h2>
<ul>
<li><a href="http://www.stat.columbia.edu/~gelman/book/BDA3.pdf">Bayesian Data Analysis 3rd Edition, Gelman</a></li>
<li><a href="https://minerva.it.manchester.ac.uk/~saralees/statbook2.pdf">Introduction to Mathematical Statistics, Hogg</a></li>
<li><a href="https://stats.stackexchange.com/questions/567944/how-can-i-sample-from-a-shifted-and-scaled-student-t-distribution-with-a-specifi">Computing a shifted and scaled t-distribution in R</a></li>
</ul>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
    </ul>
  </footer>
</article>
    </main>
    
<footer class="footer">
    <span>&copy; 2024 <a href="https://svaniksharma.github.io/">Svanik Sharma&#39;s Website</a></span>
    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
</body>

</html>
