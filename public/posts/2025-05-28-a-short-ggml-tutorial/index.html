<!DOCTYPE html>
<html lang="en" dir="auto">

<head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="noindex, nofollow">
<title>A Short GGML Tutorial | Svanik Sharma&#39;s Website</title>
<meta name="keywords" content="">
<meta name="description" content="I recently wanted to learn about GGML, a tensor and machine learning library behind popular open source versions of LLaMA and Whisper. Trying to find good resources on GGML is hard, so I thought I&rsquo;d write up some preliminary notes for anyone looking to get started.
Before reading the rest of this, please consider the following resources, especially the first link &ndash; the examples in the GGML repository are a great starting point:">
<meta name="author" content="">
<link rel="canonical" href="http://localhost:1313/posts/2025-05-28-a-short-ggml-tutorial/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.c5de734fbd88c3d21543485ffbcb1ccdda89a86a780cf987fa00199c41dbc947.css" integrity="sha256-xd5zT72Iw9IVQ0hf&#43;8sczdqJqGp4DPmH&#43;gAZnEHbyUc=" rel="preload stylesheet" as="style">
<link rel="icon" href="http://localhost:1313/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="http://localhost:1313/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="http://localhost:1313/favicon-32x32.png">
<link rel="apple-touch-icon" href="http://localhost:1313/apple-touch-icon.png">
<link rel="mask-icon" href="http://localhost:1313/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="http://localhost:1313/posts/2025-05-28-a-short-ggml-tutorial/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript>
  <script type="text/javascript">
  MathJax = {
    tex: {
      displayMath: [['$$', '$$'], ['\\[', '\\]']],
      inlineMath: [['$', '$'], ['\\(', '\\)']],
    },
  };
</script>
<script
    async
    id="MathJax-script"
    src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"
    integrity="sha384-+BSz3oj3ILMYvOBr16U9i0H4RZRmGyQQ+1q9eqr8T3skmAFrJk8GmgwgqlCZdNSo"
    crossorigin="anonymous"
    referrerpolicy="no-referrer"
    type="text/javascript"></script>



</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="http://localhost:1313/" accesskey="h" title="Svanik Sharma&#39;s Website (Alt + H)">Svanik Sharma&#39;s Website</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
                <ul class="lang-switch"><li>|</li>
                </ul>
            </div>
        </div>
        <ul id="menu">
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    
    <h1 class="post-title entry-hint-parent">
      A Short GGML Tutorial
    </h1>
    <div class="post-meta"><span title='2025-05-28 07:07:07 +0100 +0100'>May 28, 2025</span>

</div>
  </header> 
  <div class="post-content"><p>I recently wanted to learn about <a href="https://github.com/ggml-org/ggml">GGML</a>, a tensor and machine learning library behind popular open source versions of <a href="https://github.com/ggml-org/llama.cpp">LLaMA</a> and <a href="https://github.com/ggml-org/whisper.cpp">Whisper</a>. Trying to find good resources on GGML is hard, so I thought I&rsquo;d write up some preliminary notes for anyone looking to get started.</p>
<p>Before reading the rest of this, please consider the following resources, especially the first link &ndash; the examples in the GGML repository are a great starting point:</p>
<ul>
<li><a href="https://github.com/ggml-org/ggml/tree/master/examples">GGML Examples</a>, especially:
<ul>
<li><a href="https://github.com/ggml-org/ggml/blob/master/examples/simple/simple-ctx.cpp">Simple Example w/ Static Context</a></li>
<li><a href="https://github.com/ggml-org/ggml/blob/master/examples/simple/simple-backend.cpp">Simple Example w/ Backend</a></li>
<li><a href="https://github.com/ggml-org/ggml/tree/master/examples/mnist">MNIST Implementation</a></li>
</ul>
</li>
<li><a href="https://huggingface.co/blog/introduction-to-ggml">Huggingface Article</a></li>
<li><a href="https://xsxszab.github.io/posts/ggml-deep-dive-ii/">Deep Dive into GGML</a> (this is pretty advanced since it discusses GGML internals, too)</li>
</ul>
<h2 id="tutorial-regression">Tutorial Regression<a hidden class="anchor" aria-hidden="true" href="#tutorial-regression">#</a></h2>
<p>In order to get started with GGML, our goal will be to implement a simple program that can perform a linear regression. In particular, we will fit the function:</p>
<p>$$ y = ax + b $$</p>
<p>given data points $(x_i, y_i)$, $i \in {1, &hellip;, n}$. All the code presented henceforth is available <a href="https://github.com/svaniksharma/ggml-tutorial">here</a>. We start off in <code>main</code> doing the <a href="https://github.com/svaniksharma/ggml-tutorial/blob/74bdf6a8d231bf21efb73b21b592515bd22cda0b/src/tutorial.cpp#L83C3-L87C51">following</a>:</p>
<div class="highlight"><div style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">5
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span>  <span style="color:#75715e">/* TutorialRegression: Compute a * x + b where a = 3, b = 4, x = 5, (end result should be 19) */</span>
</span></span><span style="display:flex;"><span>  TutorialRegression regressor;
</span></span><span style="display:flex;"><span>  regressor.set_params(<span style="color:#ae81ff">3.0f</span>, <span style="color:#ae81ff">4.0f</span>);
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">float</span> result <span style="color:#f92672">=</span> regressor.forward(<span style="color:#ae81ff">5.0f</span>);
</span></span><span style="display:flex;"><span>  std<span style="color:#f92672">::</span>cout <span style="color:#f92672">&lt;&lt;</span> <span style="color:#e6db74">&#34;Tutorial Result: &#34;</span> <span style="color:#f92672">&lt;&lt;</span> result <span style="color:#f92672">&lt;&lt;</span> <span style="color:#e6db74">&#34;</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#34;</span>;
</span></span></code></pre></td></tr></table>
</div>
</div><p>The <code>TutorialRegression</code> object is used to compute $ax + b$ where $a = 3, b = 4, \text{ and } x = 5$. This object is something we create to encapsulate the regression process and, in particular, we are only going to use it to do inference (so no training). The internals are written in GGML, which we&rsquo;ll dive into right now, starting with the <a href="https://github.com/svaniksharma/ggml-tutorial/blob/74bdf6a8d231bf21efb73b21b592515bd22cda0b/include/tutorial.h#L15C3-L34C4">constructor</a> in <code>tutorial.h</code>:</p>
<div class="highlight"><div style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">10
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">11
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">12
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">13
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">14
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">15
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">16
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">17
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">18
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">19
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span>  TutorialRegression() {
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">struct</span> <span style="color:#a6e22e">ggml_init_params</span> params {
</span></span><span style="display:flex;"><span>      <span style="color:#75715e">/* .mem_size = */</span> <span style="color:#ae81ff">1024</span> <span style="color:#f92672">*</span> <span style="color:#a6e22e">ggml_tensor_overhead</span>(), 
</span></span><span style="display:flex;"><span>      <span style="color:#75715e">/* .mem_buffer = */</span> <span style="color:#66d9ef">nullptr</span>,
</span></span><span style="display:flex;"><span>      <span style="color:#75715e">/* .no_alloc = */</span> false
</span></span><span style="display:flex;"><span>    };
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">/* We initialize a context. 
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">     * The context keeps track of the tensors and operations between them. 
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">     * In this case, we are also using it to perform the computation. */</span>
</span></span><span style="display:flex;"><span>    _ctx <span style="color:#f92672">=</span> ggml_init(params); 
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">// Using the context, we construct the computational graph for y = a * x + b.
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>    <span style="color:#75715e">// Note that no computation is actually being performed.
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>    <span style="color:#75715e">// This is only done to build the graph. 
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>    _a <span style="color:#f92672">=</span> ggml_new_tensor_1d(_ctx, GGML_TYPE_F32, <span style="color:#ae81ff">1</span>);
</span></span><span style="display:flex;"><span>    _b <span style="color:#f92672">=</span> ggml_new_tensor_1d(_ctx, GGML_TYPE_F32, <span style="color:#ae81ff">1</span>);
</span></span><span style="display:flex;"><span>    _x <span style="color:#f92672">=</span> ggml_new_tensor_1d(_ctx, GGML_TYPE_F32, <span style="color:#ae81ff">1</span>);
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">struct</span> <span style="color:#a6e22e">ggml_tensor</span> <span style="color:#f92672">*</span>ax <span style="color:#f92672">=</span> ggml_mul(_ctx, _a, _x);
</span></span><span style="display:flex;"><span>    _result <span style="color:#f92672">=</span> ggml_add(_ctx, ax, _b);
</span></span><span style="display:flex;"><span>  }
</span></span></code></pre></td></tr></table>
</div>
</div><p>This class has some private variables, which you can identify by the underscore prefix. The first line initializes <code>params</code>, which contains three fields of importance to us: <code>mem_size</code>, <code>mem_buffer</code>, and <code>no_alloc</code>. <code>mem_size</code> specifies the amount of memory to allocate for the following operations. Though we could try to calculate it, we will just allocate <code>1024 * ggml_tensor_overhead()</code>, i.e, the amount of memory needed to allocate 1024 tensors. This is almost certainly too much, but it suffices for this example. <code>mem_buffer</code> allows us to specify a memory buffer for GGML to use, but we can set it to null and let GGML take care of finding the memory for us. Finally, <code>no_alloc</code> is used to tell GGML whether allocate memory for the computational graph or not. In this case, we have set it to <code>false</code>, meaning we want GGML to allocate the memory for the computational graph for us. This will be important later.</p>
<p>After initializing <code>params</code>, we pass it to <code>_ctx</code>. This creates a <code>ggml_context</code>, which is used to track tensor metadata and will help us build the computational graph. Using <code>_ctx</code>, we initialize <code>_a</code>, <code>_b</code>, and <code>_x</code> as new tensors (in this case, the &ldquo;tensors&rdquo; are just 32-bit floats). Note that we have not actually allocated any memory nor have we initialized the tensors with any particular value. At this point, the tensors are just objects in a computational graph. The next few lines make this clear. We &ldquo;multiply&rdquo; <code>_a</code> by <code>_x</code> and then we &ldquo;add&rdquo; <code>_b</code> to get <code>_result</code>. Using the <code>_ctx</code>, this creates a computational graph that tells GGML how to compute $y = ax + b$ (in this case, $y$ is <code>_result</code>).</p>
<p>Now, we can move into <code>tutorial.cpp</code>. The next line after creating the <code>TutorialRegression</code> object in <code>main</code> is <code>regressor.set_params(3.0f, 4.0f);</code>. We can now examine the <code>set_params</code> <a href="https://github.com/svaniksharma/ggml-tutorial/blob/e82d5ff8560c1d65fd3813bfe5544b215025f53c/src/tutorial.cpp#L10-L15">method</a>:</p>
<div class="highlight"><div style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">6
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#66d9ef">void</span> TutorialRegression<span style="color:#f92672">::</span>set_params(<span style="color:#66d9ef">const</span> <span style="color:#66d9ef">float</span> a, <span style="color:#66d9ef">const</span> <span style="color:#66d9ef">float</span> b) {
</span></span><span style="display:flex;"><span>  <span style="color:#75715e">// This just sets the values of `_a` and `_b`. This is used once we are 
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>  <span style="color:#75715e">// ready to perform the computation (see `forward`).
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>  ggml_set_f32(_a, a);
</span></span><span style="display:flex;"><span>  ggml_set_f32(_b, b);
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></td></tr></table>
</div>
</div><p>This is where we actually fill the tensors with some data. Since we are just using the CPU, we can call <code>ggml_set_f32</code> to set the data (this is not the same if we are using a GPU or some other &ldquo;backend&rdquo;).
Now, for the interesting part. This is the line <code>float result = regressor.forward(5.0f);</code> in <code>main</code>. This is what the <code>forward</code> <a href="https://github.com/svaniksharma/ggml-tutorial/blob/e82d5ff8560c1d65fd3813bfe5544b215025f53c/src/tutorial.cpp#L17C1-L28C2">method</a> does:</p>
<div class="highlight"><div style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">10
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">11
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">12
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#66d9ef">float</span> TutorialRegression<span style="color:#f92672">::</span>forward(<span style="color:#66d9ef">const</span> <span style="color:#66d9ef">float</span> x) {
</span></span><span style="display:flex;"><span>  <span style="color:#75715e">// Set the input tensor `_x`
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>  ggml_set_f32(_x, x);
</span></span><span style="display:flex;"><span>  <span style="color:#75715e">// Create a new graph using the context
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>  <span style="color:#66d9ef">struct</span> <span style="color:#a6e22e">ggml_cgraph</span> <span style="color:#f92672">*</span>cf <span style="color:#f92672">=</span> ggml_new_graph(_ctx);
</span></span><span style="display:flex;"><span>  <span style="color:#75715e">// Use the new graph and the output tensor to build the graph outwards
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>  ggml_build_forward_expand(cf, _result);
</span></span><span style="display:flex;"><span>  <span style="color:#75715e">// Use the graph and context to compute the result (use 1 thread)
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>  ggml_graph_compute_with_ctx(_ctx, cf, <span style="color:#ae81ff">1</span>);
</span></span><span style="display:flex;"><span>  <span style="color:#75715e">// get the result from the tensor (since this tensor holds 1 value, we pass index 0).
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>  <span style="color:#66d9ef">return</span> <span style="color:#a6e22e">ggml_get_f32_1d</span>(_result, <span style="color:#ae81ff">0</span>);
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></td></tr></table>
</div>
</div><p>Like in <code>set_params</code>, we fill the input tensor <code>_x</code> with some actual data. To actually <em>do</em> the computation, we create a computational graph from <code>_ctx</code> called <code>cf</code>. We then tell GGML to build the graph out and put the result in <code>_result</code> by calling <code>ggml_build_forward_expand</code>. Finally, we use <code>ggml_graph_compute_with_ctx</code> to actually compute the result. Note that <code>_result</code> is a tensor, so in order to extract the floating point data, we use <code>ggml_get_f32_1d</code>.</p>
<p>If you run this, you should notice the line <code>Tutorial Result: 19</code> in the output.</p>
<h2 id="backend-regression">Backend Regression<a hidden class="anchor" aria-hidden="true" href="#backend-regression">#</a></h2>
<p>Obviously, GGML wouldn&rsquo;t be very useful if we could only compute on the CPU. We are also able to use the GPU and, more generally, different <em>backends</em> in order to do inference. Furthermore, you can train models with GGML to. We will do both to complete our regression example. First, we&rsquo;ll look at inference (as we did with <code>TutorialRegression</code>) and then we&rsquo;ll look at training.</p>
<h3 id="inference">Inference<a hidden class="anchor" aria-hidden="true" href="#inference">#</a></h3>
<p>In <code>main</code>, we do the <a href="https://github.com/svaniksharma/ggml-tutorial/blob/ca4e326a98790e3a4849e255cb89adf8e84c4db7/src/tutorial.cpp#L88C3-L92C53">following</a>:</p>
<div class="highlight"><div style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">5
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span>  <span style="color:#75715e">/* Do the same thing as TutorialRegression, but with a backend (end result should be 19) */</span>
</span></span><span style="display:flex;"><span>  BackendRegression<span style="color:#f92672">&lt;</span><span style="color:#66d9ef">float</span><span style="color:#f92672">&gt;</span> backend_regressor;
</span></span><span style="display:flex;"><span>  backend_regressor.set_params(<span style="color:#ae81ff">3.0f</span>, <span style="color:#ae81ff">4.0f</span>);
</span></span><span style="display:flex;"><span>  result <span style="color:#f92672">=</span> regressor.forward(<span style="color:#ae81ff">5.0f</span>);
</span></span><span style="display:flex;"><span>  std<span style="color:#f92672">::</span>cout <span style="color:#f92672">&lt;&lt;</span> <span style="color:#e6db74">&#34;Backend result: &#34;</span> <span style="color:#f92672">&lt;&lt;</span> result <span style="color:#f92672">&lt;&lt;</span> <span style="color:#e6db74">&#34;</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#34;</span>;
</span></span></code></pre></td></tr></table>
</div>
</div><p>Similar to <code>TutorialRegression</code>, <code>BackendRegression</code> encapsulates all the GGML stuff. This is performing the exact same calculation as before, but we will now use the GPU to perform the computation (you will need CUDA if you want to do this). Let&rsquo;s start with the <a href="https://github.com/svaniksharma/ggml-tutorial/blob/ca4e326a98790e3a4849e255cb89adf8e84c4db7/include/tutorial.h#L89C3-L153C4">constructor</a>:</p>
<div class="highlight"><div style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">10
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">11
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">12
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">13
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">14
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">15
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">16
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">17
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">18
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">19
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">20
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">21
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">22
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">23
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">24
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">25
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">26
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">27
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">28
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">29
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">30
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">31
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">32
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">33
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">34
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">35
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">36
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">37
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">38
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">39
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">40
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">41
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">42
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">43
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">44
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">45
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">46
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">47
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">48
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">49
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">50
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">51
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">52
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">53
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">54
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">55
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">56
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">57
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">58
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">59
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">60
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">61
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">62
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">63
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">64
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">65
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span>  BackendRegression() {
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">// This can work for either double or float.
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>    <span style="color:#75715e">// Notice that .no_alloc is true here. We want to allocate memory explicitly.
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>    <span style="color:#66d9ef">struct</span> <span style="color:#a6e22e">ggml_init_params</span> params <span style="color:#f92672">=</span> {
</span></span><span style="display:flex;"><span>      <span style="color:#75715e">/* .mem_size = */</span> <span style="color:#ae81ff">1024</span> <span style="color:#f92672">*</span> <span style="color:#a6e22e">ggml_tensor_overhead</span>(),
</span></span><span style="display:flex;"><span>      <span style="color:#75715e">/* .mem_buffer = */</span> <span style="color:#66d9ef">nullptr</span>,
</span></span><span style="display:flex;"><span>      <span style="color:#75715e">/* .no_alloc = */</span> true
</span></span><span style="display:flex;"><span>    };
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">// Like before, we determine whether we are dealing with float or double.
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>    <span style="color:#66d9ef">enum</span> <span style="color:#a6e22e">ggml_type</span> tensor_type;
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">if</span> (std<span style="color:#f92672">::</span>is_same<span style="color:#f92672">&lt;</span>T, <span style="color:#66d9ef">float</span><span style="color:#f92672">&gt;::</span>value)
</span></span><span style="display:flex;"><span>      tensor_type <span style="color:#f92672">=</span> GGML_TYPE_F32;
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">else</span> <span style="color:#a6e22e">if</span> (std<span style="color:#f92672">::</span>is_same<span style="color:#f92672">&lt;</span>T, <span style="color:#66d9ef">double</span><span style="color:#f92672">&gt;::</span>value)
</span></span><span style="display:flex;"><span>      tensor_type <span style="color:#f92672">=</span> GGML_TYPE_F64;
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">else</span>
</span></span><span style="display:flex;"><span>      <span style="color:#a6e22e">GGML_ASSERT</span>(false);
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">// We now allocate a context, but we will be using a backend for computations. 
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>    <span style="color:#75715e">// In this case, the only purpose of the *static* context is to create the tensor metadata.
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>    _ctx_static <span style="color:#f92672">=</span> ggml_init(params);
</span></span><span style="display:flex;"><span>    _a <span style="color:#f92672">=</span> ggml_new_tensor_1d(_ctx_static, tensor_type, <span style="color:#ae81ff">1</span>);
</span></span><span style="display:flex;"><span>    _b <span style="color:#f92672">=</span> ggml_new_tensor_1d(_ctx_static, tensor_type, <span style="color:#ae81ff">1</span>);
</span></span><span style="display:flex;"><span>    _x <span style="color:#f92672">=</span> ggml_new_tensor_1d(_ctx_static, tensor_type, <span style="color:#ae81ff">1</span>);
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">// Since we are going to be using this for both training and inference, we need to specify the 
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>    <span style="color:#75715e">// model inputs, outputs, and parameters. In y = a * x + b, a and b are parameters, x is an input.
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>    ggml_set_input(_x);
</span></span><span style="display:flex;"><span>    ggml_set_param(_a);
</span></span><span style="display:flex;"><span>    ggml_set_param(_b);
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">// Now we initialize the backend. In this case, we use CUDA as the backend.
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>    <span style="color:#75715e">// The backend buffer is returned after we allocate the tensors using the static context + backend.
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>    <span style="color:#75715e">// We will need to keep the backend buffer to free it later.
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>    _backend <span style="color:#f92672">=</span> ggml_backend_cuda_init(<span style="color:#ae81ff">0</span>);
</span></span><span style="display:flex;"><span>    _backend_buffer <span style="color:#f92672">=</span> ggml_backend_alloc_ctx_tensors(_ctx_static, _backend);
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">// Now, we create the *compute* context. This is what does inference and training. 
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>    <span style="color:#75715e">// Again, .no_alloc = true because we will explicitly allocate the graph. Calculating the memory needed is easy
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>    <span style="color:#75715e">// and we don&#39;t have to allocate a sufficiently large amount or check with ggml_mem.
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>    <span style="color:#75715e">// By default, GGML allocates 2048 nodes (GGML_DEFAULT_GRAPH_SIZE) when allocating a graph.
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>    <span style="color:#75715e">// Each of the 2048 nodes carries overhead since they are essentially tensors. Since we are 
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>    <span style="color:#75715e">// doing inference and training, we need to allocate 1 graph for the forward pass, 1 for the backward pass.
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>    params <span style="color:#f92672">=</span> {
</span></span><span style="display:flex;"><span>      ggml_tensor_overhead() <span style="color:#f92672">*</span> GGML_DEFAULT_GRAPH_SIZE <span style="color:#f92672">+</span> <span style="color:#ae81ff">2</span> <span style="color:#f92672">*</span> ggml_graph_overhead(),
</span></span><span style="display:flex;"><span>      <span style="color:#66d9ef">nullptr</span>,
</span></span><span style="display:flex;"><span>      true
</span></span><span style="display:flex;"><span>    };
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">// This time, we use the *compute* context in order to construct the computational graph.
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>    <span style="color:#75715e">// Note that after we get `_result`, we use ggml_set_output to mark _result as the output tensor.
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>    _ctx_compute <span style="color:#f92672">=</span> ggml_init(params);
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">struct</span> <span style="color:#a6e22e">ggml_tensor</span> <span style="color:#f92672">*</span>ax <span style="color:#f92672">=</span> ggml_mul(_ctx_compute, _a, _x);
</span></span><span style="display:flex;"><span>    _result <span style="color:#f92672">=</span> ggml_add(_ctx_compute, ax, _b);
</span></span><span style="display:flex;"><span>    ggml_set_output(_result);
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">// To do training, we need a backend scheduler. The backend scheduler allows us to manage several backends 
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>    <span style="color:#75715e">// at once for inference and training. In this case, we really only need it to fit the model. We push the CPU
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>    <span style="color:#75715e">// backend as well since it is required as a fallback.
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>    std<span style="color:#f92672">::</span>vector<span style="color:#f92672">&lt;</span>ggml_backend_t<span style="color:#f92672">&gt;</span> backends;
</span></span><span style="display:flex;"><span>    backends.push_back(_backend);
</span></span><span style="display:flex;"><span>    backends.push_back(ggml_backend_cpu_init());
</span></span><span style="display:flex;"><span>    _backend_sched <span style="color:#f92672">=</span> ggml_backend_sched_new(backends.data(), <span style="color:#66d9ef">nullptr</span>, backends.size(), GGML_DEFAULT_GRAPH_SIZE, false, true);
</span></span><span style="display:flex;"><span>    std<span style="color:#f92672">::</span>cout <span style="color:#f92672">&lt;&lt;</span> <span style="color:#e6db74">&#34;Using &#34;</span> <span style="color:#f92672">&lt;&lt;</span> ggml_backend_name(_backend) <span style="color:#f92672">&lt;&lt;</span> <span style="color:#e6db74">&#34; as backend</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#34;</span>;
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">// After constructing the computational graph, we need to allocate the graph.
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>    <span style="color:#75715e">// ggml_gallocr_new needs to know the backend buffer type. In this case, we 
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>    <span style="color:#75715e">// find the backend buffer type using ggml_backend_get_default_buffer_type.
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>    _gf <span style="color:#f92672">=</span> ggml_new_graph(_ctx_compute);
</span></span><span style="display:flex;"><span>    ggml_build_forward_expand(_gf, _result);
</span></span><span style="display:flex;"><span>    _allocr <span style="color:#f92672">=</span> ggml_gallocr_new(ggml_backend_get_default_buffer_type(_backend));
</span></span><span style="display:flex;"><span>    ggml_gallocr_alloc_graph(_allocr, _gf); 
</span></span><span style="display:flex;"><span>  }
</span></span></code></pre></td></tr></table>
</div>
</div><p>There is a lot more going on here, but we&rsquo;ll go through it slowly. Note that this class takes a template parameter <code>T</code>, which allows us to specify whether we want to use <code>float</code> or <code>double</code> for the input or output values. This time around, we are going to create a <em>static</em> context and a <em>compute</em> context. The static context will be used to store tensor metadata and allocate them on the backend (the GPU). The compute context will be used to construct the computational graph and then perform the computation.</p>
<ul>
<li><strong>Lines 4-8</strong>: The only difference from <code>TutorialRegression</code> is that we specify <code>no_alloc</code> to be <code>true</code>. This is because we will explicitly allocate the metadata for the tensors using the backend.</li>
<li><strong>Lines 10-16</strong>: Since this class takes a template parameter, we determine the type of tensor (32-bit or 64-bit floating point) before proceeding to initialize the static context.</li>
<li><strong>Lines 19-22</strong>: We initialize the static context and then create the three tensors <code>_a</code>, <code>_b</code>, <code>_x</code> as before.</li>
<li><strong>Lines 25-27</strong>: Since we will be training this model, we need to specify the inputs, parameters, and outputs. This is different from <code>TutorialRegression</code>. In this case, we set <code>_x</code> as the input and <code>_a</code> and <code>_b</code> as the input. We will set <code>_result</code> to be the output later.</li>
<li><strong>Lines 31-32</strong>: We initialize the CUDA backend and &ndash; since we set <code>no_alloc</code> to <code>true</code>, we now explicitly allocate the tensor metadata we created with the static context using the GPU backend.</li>
<li><strong>Lines 39-43</strong>: Now we create the compute context. We set <code>no_alloc</code> to <code>true</code> as before, since we will explicitly allocate the computational graph.</li>
<li><strong>Lines 46-49</strong>: Using the <code>params</code> we created, we initialize the compute context and then construct the computational graph.</li>
<li><strong>Lines 53-57</strong>: To do training, we will need to create a backend scheduler. Note that we need to include the CPU backend in the list of backends we supply to <code>ggml_backend_sched_new</code> as a fallback.</li>
<li><strong>Lines 61-64</strong>: Since we specified <code>no_alloc = true</code>, we need to explicitly allocate the graph using the compute context. Computational graphs are meant to be allocated only once in GGML, but they can be used multiple times for computation once they are allocated.</li>
</ul>
<p>Now, we <a href="https://github.com/svaniksharma/ggml-tutorial/blob/ca4e326a98790e3a4849e255cb89adf8e84c4db7/src/tutorial.cpp#L30C1-L36C2l">look</a>  at <code>set_params</code>. This time, we can&rsquo;t use <code>ggml_set_f32</code> since we are using a backend. Instead, we use <code>ggml_backend_tensor_set</code>:</p>
<div class="highlight"><div style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">7
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#66d9ef">template</span><span style="color:#f92672">&lt;</span><span style="color:#66d9ef">typename</span> T<span style="color:#f92672">&gt;</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">void</span> BackendRegression<span style="color:#f92672">&lt;</span>T<span style="color:#f92672">&gt;::</span>set_params(<span style="color:#66d9ef">const</span> T a, <span style="color:#66d9ef">const</span> T b) {
</span></span><span style="display:flex;"><span>  <span style="color:#75715e">// Similar to set_params for TutorialRegression. But now, we are using a backend.
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>  <span style="color:#75715e">// We have to use ggml_backend_tensor_set since ggml_set_f32 is used specifically for the CPU backend. 
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>  ggml_backend_tensor_set(_a, <span style="color:#f92672">&amp;</span>a, <span style="color:#ae81ff">0</span>, ggml_nbytes(_a));
</span></span><span style="display:flex;"><span>  ggml_backend_tensor_set(_b, <span style="color:#f92672">&amp;</span>b, <span style="color:#ae81ff">0</span>, ggml_nbytes(_b));
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></td></tr></table>
</div>
</div><p>Let&rsquo;s see how <code>forward</code> is implemented. It is essentially the same as before, but since we have already pre-allocated the graph, we don&rsquo;t need to call <code>ggml_build_forward_expand</code>. <a href="https://github.com/svaniksharma/ggml-tutorial/blob/ca4e326a98790e3a4849e255cb89adf8e84c4db7/src/tutorial.cpp#L38C1-L52C2">Here</a>  is the code:</p>
<div class="highlight"><div style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">10
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">11
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">12
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">13
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">14
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">15
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#66d9ef">template</span> <span style="color:#f92672">&lt;</span><span style="color:#66d9ef">typename</span> T<span style="color:#f92672">&gt;</span>
</span></span><span style="display:flex;"><span>T BackendRegression<span style="color:#f92672">&lt;</span>T<span style="color:#f92672">&gt;::</span>forward(<span style="color:#66d9ef">const</span> T x) {
</span></span><span style="display:flex;"><span>  <span style="color:#75715e">// Again, we use ggml_backend_tensor_set instead of ggml_set_f32
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>  ggml_backend_tensor_set(_x, <span style="color:#f92672">&amp;</span>x, <span style="color:#ae81ff">0</span>, ggml_nbytes(_x));
</span></span><span style="display:flex;"><span>  <span style="color:#75715e">// We already built and allocated the graph in the constructor. 
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>  <span style="color:#75715e">// Now we just have to do the computation using the backend.
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>  ggml_backend_graph_compute(_backend, _gf);
</span></span><span style="display:flex;"><span>  <span style="color:#75715e">// The result is stored in _result, but this shows an alternate way to get it.
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>  <span style="color:#75715e">// We know that the last node in the graph is the result, we we fetch the result node.
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>  <span style="color:#66d9ef">struct</span> <span style="color:#a6e22e">ggml_tensor</span> <span style="color:#f92672">*</span>result <span style="color:#f92672">=</span> ggml_graph_node(_gf, <span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>);
</span></span><span style="display:flex;"><span>  <span style="color:#75715e">// Now, we use the backend to get the data.
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>  T result_data <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>;
</span></span><span style="display:flex;"><span>  ggml_backend_tensor_get(result, <span style="color:#f92672">&amp;</span>result_data, <span style="color:#ae81ff">0</span>, ggml_nbytes(result));
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">return</span> result_data;
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></td></tr></table>
</div>
</div><p>That&rsquo;s all there is for inference! If you read the output, it should say<code>Backend result: 19</code>.</p>
<h3 id="training">Training<a hidden class="anchor" aria-hidden="true" href="#training">#</a></h3>
<p><a href="https://github.com/svaniksharma/ggml-tutorial/blob/ca4e326a98790e3a4849e255cb89adf8e84c4db7/src/tutorial.cpp#L93C3-L124C4">Here</a>  is the training portion for <code>main</code>:</p>
<div class="highlight"><div style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">10
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">11
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">12
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">13
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">14
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">15
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">16
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">17
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">18
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">19
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">20
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">21
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">22
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">23
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">24
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">25
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">26
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">27
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">28
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">29
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">30
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">31
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">32
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span>  <span style="color:#75715e">/* Create 10000 datapoints; first column is x, second column is y. This is our &#34;dataset&#34; */</span>
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">const</span> <span style="color:#66d9ef">int</span> N <span style="color:#f92672">=</span> <span style="color:#ae81ff">10000</span>;
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">float</span> matrix[N][<span style="color:#ae81ff">2</span>];
</span></span><span style="display:flex;"><span>  <span style="color:#75715e">// Randomly generate the parameters a and b.
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>  std<span style="color:#f92672">::</span>memset(matrix, <span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">2</span> <span style="color:#f92672">*</span> N <span style="color:#f92672">*</span> <span style="color:#66d9ef">sizeof</span>(<span style="color:#66d9ef">float</span>));
</span></span><span style="display:flex;"><span>  std<span style="color:#f92672">::</span>uniform_real_distribution<span style="color:#f92672">&lt;</span><span style="color:#66d9ef">float</span><span style="color:#f92672">&gt;</span> unif(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">10</span>);
</span></span><span style="display:flex;"><span>  std<span style="color:#f92672">::</span>default_random_engine re;
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">double</span> a <span style="color:#f92672">=</span> unif(re);
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">double</span> b <span style="color:#f92672">=</span> unif(re);
</span></span><span style="display:flex;"><span>  std<span style="color:#f92672">::</span>cout <span style="color:#f92672">&lt;&lt;</span> <span style="color:#e6db74">&#34;Parameters to recover: a=&#34;</span> <span style="color:#f92672">&lt;&lt;</span> a <span style="color:#f92672">&lt;&lt;</span> <span style="color:#e6db74">&#34;; b=&#34;</span> <span style="color:#f92672">&lt;&lt;</span> b <span style="color:#f92672">&lt;&lt;</span> <span style="color:#e6db74">&#34;</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#34;</span>;
</span></span><span style="display:flex;"><span>  <span style="color:#75715e">// Compute a * x + b for integer x in the interval [1, N].
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>  <span style="color:#66d9ef">for</span> (<span style="color:#66d9ef">int</span> i <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>; i <span style="color:#f92672">&lt;</span> N; i<span style="color:#f92672">++</span>) {
</span></span><span style="display:flex;"><span>    matrix[i][<span style="color:#ae81ff">0</span>] <span style="color:#f92672">=</span> <span style="color:#66d9ef">static_cast</span><span style="color:#f92672">&lt;</span><span style="color:#66d9ef">float</span><span style="color:#f92672">&gt;</span>(i<span style="color:#f92672">+</span><span style="color:#ae81ff">1</span>);
</span></span><span style="display:flex;"><span>    matrix[i][<span style="color:#ae81ff">1</span>] <span style="color:#f92672">=</span> a <span style="color:#f92672">*</span> matrix[i][<span style="color:#ae81ff">0</span>] <span style="color:#f92672">+</span> b;
</span></span><span style="display:flex;"><span>  }
</span></span><span style="display:flex;"><span>  <span style="color:#75715e">// Use the DataLoader on the matrix to create a GGML dataset.
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>  DataLoader<span style="color:#f92672">&lt;</span><span style="color:#66d9ef">float</span><span style="color:#f92672">&gt;</span> dl(matrix, N);
</span></span><span style="display:flex;"><span>  <span style="color:#75715e">// Train the backend regressor on the dataset.
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>  backend_regressor.train(dl);
</span></span><span style="display:flex;"><span>  <span style="color:#75715e">// Print the results, and evaluate at the points x = 15000, x = 20000, x = 30000
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>  std<span style="color:#f92672">::</span>cout <span style="color:#f92672">&lt;&lt;</span> <span style="color:#e6db74">&#34;Recovered parameters</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">---------------</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#34;</span>;
</span></span><span style="display:flex;"><span>  backend_regressor.print_params();
</span></span><span style="display:flex;"><span>  std<span style="color:#f92672">::</span>cout <span style="color:#f92672">&lt;&lt;</span> <span style="color:#e6db74">&#34;Evaluation on test data</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">------------</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#34;</span>;
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">float</span> test_x[] <span style="color:#f92672">=</span> { <span style="color:#ae81ff">15000.0f</span>, <span style="color:#ae81ff">20000.0f</span>, <span style="color:#ae81ff">30000.0f</span> };
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">for</span> (<span style="color:#66d9ef">int</span> i <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>; i <span style="color:#f92672">&lt;</span> <span style="color:#66d9ef">sizeof</span>(test_x) <span style="color:#f92672">/</span> <span style="color:#66d9ef">sizeof</span>(<span style="color:#66d9ef">float</span>); i<span style="color:#f92672">++</span>) {
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">auto</span> x <span style="color:#f92672">=</span> test_x[i];
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">float</span> y <span style="color:#f92672">=</span> a <span style="color:#f92672">*</span> x <span style="color:#f92672">+</span> b;
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">float</span> y_pred <span style="color:#f92672">=</span> backend_regressor.forward(x);
</span></span><span style="display:flex;"><span>    std<span style="color:#f92672">::</span>cout <span style="color:#f92672">&lt;&lt;</span> <span style="color:#e6db74">&#34;x = &#34;</span> <span style="color:#f92672">&lt;&lt;</span> x <span style="color:#f92672">&lt;&lt;</span> <span style="color:#e6db74">&#34;</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#34;</span>;
</span></span><span style="display:flex;"><span>    std<span style="color:#f92672">::</span>cout <span style="color:#f92672">&lt;&lt;</span> <span style="color:#e6db74">&#34;y: &#34;</span> <span style="color:#f92672">&lt;&lt;</span> y <span style="color:#f92672">&lt;&lt;</span> <span style="color:#e6db74">&#34;</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#34;</span>;
</span></span><span style="display:flex;"><span>    std<span style="color:#f92672">::</span>cout <span style="color:#f92672">&lt;&lt;</span> <span style="color:#e6db74">&#34;y pred: &#34;</span> <span style="color:#f92672">&lt;&lt;</span> y_pred <span style="color:#f92672">&lt;&lt;</span> <span style="color:#e6db74">&#34;</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#34;</span>;
</span></span><span style="display:flex;"><span>  }
</span></span></code></pre></td></tr></table>
</div>
</div><p>In particular, let&rsquo;s look at the <code>train</code> <a href="https://github.com/svaniksharma/ggml-tutorial/blob/ca4e326a98790e3a4849e255cb89adf8e84c4db7/src/tutorial.cpp#L54C1-L70C2">method</a>:</p>
<div class="highlight"><div style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">10
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">11
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">12
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">13
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">14
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">15
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">16
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">17
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#66d9ef">template</span><span style="color:#f92672">&lt;</span><span style="color:#66d9ef">typename</span> T<span style="color:#f92672">&gt;</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">void</span> BackendRegression<span style="color:#f92672">&lt;</span>T<span style="color:#f92672">&gt;::</span>train(<span style="color:#66d9ef">const</span> DataLoader<span style="color:#f92672">&lt;</span>T<span style="color:#f92672">&gt;</span> <span style="color:#f92672">&amp;</span>dl) {
</span></span><span style="display:flex;"><span>  <span style="color:#75715e">/* We train the model on the dataset. Here are the parameters:
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">   * backend_sched: The backend scheduler (we made this in the constructor) 
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">   * ctx_compute: The compute context (we made this in the constructor, too)
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">   * inputs: In this case, it is the tensor, `_x`. 
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">   * outputs: In this case, it is the tensor, `_result`. 
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">   * dataset: A ggml_opt_dataset_t. We made this inside of the DataLoader `dl`.
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">   * loss_type: A loss type (in this case, we use mean squared error). 
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">   * get_opt_pars: A callback that returns the ggml_opt_get_optimizer_params. In this case, we use 
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">   * the default parameters.
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">   * nepoch: The number of epochs.
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">   * nbatch_logical: How many values per batch.
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">   * val_split: What percentage of the data should we use for validation? We don&#39;t really need this in this example. 
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">   * silent: do not print diagnostic output to stderr */</span>
</span></span><span style="display:flex;"><span>   ggml_opt_fit(_backend_sched, _ctx_compute, _x, _result, dl.get_dataset(), GGML_OPT_LOSS_TYPE_MEAN_SQUARED_ERROR, ggml_opt_get_default_optimizer_params, <span style="color:#ae81ff">5</span>, <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">0.2f</span>, true);
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></td></tr></table>
</div>
</div><p>As you can see, it is only one line &ndash; a call to <code>ggml_opt_fit</code>. We pass the <code>_backend_sched</code> that we initialized in the constructor. We also pass in a <code>DataLoader</code> object, which returns a <code>ggml_opt_dataset_t</code> using the method <code>get_dataset</code>. A majority of the work goes into making the <code>ggml_opt_dataset_t</code>. <a href="https://github.com/svaniksharma/ggml-tutorial/blob/ca4e326a98790e3a4849e255cb89adf8e84c4db7/include/tutorial.h#L50C3-L77C4">Here</a>  is the constructor of <code>DataLoader</code>:</p>
<div class="highlight"><div style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">10
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">11
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">12
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">13
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">14
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">15
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">16
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">17
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">18
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">19
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">20
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">21
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">22
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">23
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">24
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">25
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">26
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">27
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">28
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span>  DataLoader(<span style="color:#66d9ef">const</span> T matrix[][<span style="color:#ae81ff">2</span>], <span style="color:#66d9ef">const</span> size_t N) {
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">// This can work for either double or float.
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>    <span style="color:#66d9ef">enum</span> <span style="color:#a6e22e">ggml_type</span> dataset_type;
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">if</span> (std<span style="color:#f92672">::</span>is_same<span style="color:#f92672">&lt;</span>T, <span style="color:#66d9ef">float</span><span style="color:#f92672">&gt;::</span>value)
</span></span><span style="display:flex;"><span>      dataset_type <span style="color:#f92672">=</span> GGML_TYPE_F32;
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">else</span> <span style="color:#a6e22e">if</span> (std<span style="color:#f92672">::</span>is_same<span style="color:#f92672">&lt;</span>T, <span style="color:#66d9ef">double</span><span style="color:#f92672">&gt;::</span>value)
</span></span><span style="display:flex;"><span>      dataset_type <span style="color:#f92672">=</span> GGML_TYPE_F64;
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">else</span>
</span></span><span style="display:flex;"><span>      <span style="color:#a6e22e">GGML_ASSERT</span>(false);
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">/* This creates a dataset. The arguments are as follows:
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">     * type_data: We set this above: 32-bit float or 64-bit float.
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">     * type_label: Same as above. In this case, it&#39;s the same type.
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">     * ne_datapoint: Number of elements per datapoint (i.e, how many features per datapoint) 
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">     * ne_label: Number of elements per label (i.e, how many outputs/targets/dependent variables do you have)
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">     * ndata: The number of datapoints and labels
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">     * ndata_shard: A shard is the unit along which a datapoint is shuffled. This is the number of points per shard. */</span>
</span></span><span style="display:flex;"><span>    _dataset <span style="color:#f92672">=</span> ggml_opt_dataset_init(dataset_type, dataset_type, <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>, N, <span style="color:#ae81ff">1</span>);
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">// Once the dataset is created, the underlying tensors are allocated for you based on the arguments passed above. ^^^
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>    <span style="color:#75715e">// The following code gets the underlying tensors, and then uses ggml_get_data to get the actual buffer inside of the tensor. We then use the matrix passed in the constructor (first column datapoint, second column labels) to set these underlying buffers.
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>    <span style="color:#66d9ef">struct</span> <span style="color:#a6e22e">ggml_tensor</span> <span style="color:#f92672">*</span>data <span style="color:#f92672">=</span> ggml_opt_dataset_data(_dataset);
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">struct</span> <span style="color:#a6e22e">ggml_tensor</span> <span style="color:#f92672">*</span>labels <span style="color:#f92672">=</span> ggml_opt_dataset_labels(_dataset);
</span></span><span style="display:flex;"><span>    T <span style="color:#f92672">*</span>data_buf <span style="color:#f92672">=</span> <span style="color:#66d9ef">static_cast</span><span style="color:#f92672">&lt;</span>T <span style="color:#f92672">*&gt;</span>(ggml_get_data(data));
</span></span><span style="display:flex;"><span>    T <span style="color:#f92672">*</span>labels_buf <span style="color:#f92672">=</span> <span style="color:#66d9ef">static_cast</span><span style="color:#f92672">&lt;</span>T <span style="color:#f92672">*&gt;</span>(ggml_get_data(labels));
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span> (<span style="color:#66d9ef">int</span> i <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>; i <span style="color:#f92672">&lt;</span> N; i<span style="color:#f92672">++</span>) {
</span></span><span style="display:flex;"><span>      data_buf[i] <span style="color:#f92672">=</span> matrix[i][<span style="color:#ae81ff">0</span>];
</span></span><span style="display:flex;"><span>      labels_buf[i] <span style="color:#f92672">=</span> matrix[i][<span style="color:#ae81ff">1</span>];
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>  }
</span></span></code></pre></td></tr></table>
</div>
</div><p>Lines 3-9 determine whether we are using <code>float</code> or <code>double</code> for the dataset. Then, line 17 creates the dataset using <code>ggml_opt_dataset_init</code> (note that in this case, the output and input have the same type, though they could also be of different types). Lines 20-27 populate the <code>_dataset</code> with actual data.</p>
<p>And that&rsquo;s it for training! The output for the training section should look something like this:</p>
<pre tabindex="0"><code>Parameters to recover: a=1.00007; b=2.18384
&lt;some diagonistic output...&gt;
Recovered parameters
---------------
a: 1.00007
b: 2.19581
Evaluation on test data
------------
x = 15000
y: 15003.2
y pred: 15003.2
x = 20000
y: 20003.6
y pred: 20003.5
x = 30000
y: 30004.3
y pred: 30004.2
</code></pre><p>Note that $a$ and $b$ are generated randomly, so the numbers themselves might be different. But, if training goes correctly, the <code>Parameters to recover</code> and the <code>Recovered parameters</code> should be close in value. The predicted results should also closely match the actual <code>y</code> values, too.</p>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
    </ul>
  </footer>
</article>
    </main>
    
<footer class="footer">
    <span>&copy; 2025 <a href="http://localhost:1313/">Svanik Sharma&#39;s Website</a></span>
    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
</body>

</html>
