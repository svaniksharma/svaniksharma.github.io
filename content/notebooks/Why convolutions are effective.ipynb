{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3e006a3-34d1-4539-b233-8a0cec4cac96",
   "metadata": {},
   "source": [
    "## Why convolutions are effective\n",
    "\n",
    "Convolutional neural networks have seen great success in computer vision tasks. However, why is this architecture so effective? This article hopes to elucidate the apparent efficacy of convolutional networks in many computer vision tasks. We'll approach this by training a convolutional network on the Fashion MNIST dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8a0f43-b232-493f-b526-b810a636f8de",
   "metadata": {},
   "source": [
    "### A brief look at the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68968cca",
   "metadata": {},
   "source": [
    "First, we make some necessary imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d756629-4f23-45bb-a6fa-ff4a639af11d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torchinfo import summary\n",
    "\n",
    "device_name = None\n",
    "if torch.cuda.is_available():\n",
    "    device_name = 'cuda'\n",
    "else:\n",
    "    device_name = 'cpu'\n",
    "device = torch.device(device_name)\n",
    "print('Using device: ' + device_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae3e03f",
   "metadata": {},
   "source": [
    "Then, we load the dataset and display it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3896633-2edd-40ba-ba24-5e59588728fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will download the dataset to a local directory if not downloaded already\n",
    "# otherwise looks for a directory named \"fashion_mnist\"\n",
    "train_dataset = torchvision.datasets.FashionMNIST(root='fashion_mnist', download=True, train=True, transform=ToTensor())\n",
    "test_dataset = torchvision.datasets.FashionMNIST(root='fashion_mnist', download=True, train=False, transform=ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b75773e7-5082-439a-8c7f-4cd857e8aae9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels = [\n",
    "    'T-shirt/top',\n",
    "    'Trouser',\n",
    "    'Pullover',\n",
    "    'Dress',\n",
    "    'Coat',\n",
    "    'Sandal',\n",
    "    'Shirt',\n",
    "    'Sneaker',\n",
    "    'Bag',\n",
    "    'Ankle Boot'\n",
    "]\n",
    "figure = plt.figure(figsize=(5, 5))\n",
    "rows, cols = 3, 3\n",
    "for i in range(1, cols * rows + 1):\n",
    "    sample_idx = torch.randint(len(train_dataset), size=(1,)).item()\n",
    "    img, label = train_dataset[sample_idx]\n",
    "    figure.add_subplot(rows, cols, i)\n",
    "    plt.title(labels[label])\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(img.squeeze(), cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "029ac342",
   "metadata": {},
   "source": [
    "The FashionMNIST dataset has 9 classes (indicated in the `labels` array above) and they each consist of $28 \\times 28$ grayscale images. Unlike RGB, this means that each pixel has only one value. We can verify this by looking at an example from the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e110066-4ad5-433e-9ce0-2cccdcaeaa34",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_idx = torch.randint(len(train_dataset), size=(1,)).item()\n",
    "img, _ = train_dataset[sample_idx]\n",
    "print(f'Image shape: {img.shape}')\n",
    "max_pixel_val = torch.max(img)\n",
    "min_pixel_val = torch.min(img)\n",
    "print(f'Range of image pixels: {min_pixel_val} to {max_pixel_val}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb49e455-13ee-4ce6-910e-e6946932467b",
   "metadata": {},
   "source": [
    "### What are convolutions?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3550b30b",
   "metadata": {},
   "source": [
    "The convolution operation is defined as below:\n",
    "\n",
    "$$C(j, k) = \\sum_{l} \\sum_{m} I(j + l, k + m) K(l, m)$$\n",
    "\n",
    "where $I$ is an image and $K$ is called the *kernel*. The above equation gives the computation for the $j, k$ entry of $C$. In this case, $K$ is a learnable parameter. The resulting $C$ is called a feature map. Though the above is called a convolution in machine learning literature, it is actually called the \"[cross correlation](https://en.wikipedia.org/wiki/Cross-correlation)\" operation, which comes from signal processing and statistics. The main reason we use convolutional layers is because they retain \"inductive bias\", i.e, they are able to exploit the properties of images better than a typical multilayer-perception network. In particular, convolutions maintain *equivariance*, which essentially means that if an input image is transformed and passed through a convolutional layer, the feature map will be transformed in a consistent manner. In our image classification example, we seek a special case of equivariance, namely, *invariance*, whereby a translation, rotation, or scaling of the input image will not affect its classification. We will implement the convolution operation as well as some additional features to demonstrate how it works."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf0680a-842f-4d37-98ed-2d9da82c32a4",
   "metadata": {},
   "source": [
    "### Creating a convolutional neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e747ba7c-70db-452c-88d5-cc21613ec48e",
   "metadata": {},
   "source": [
    "#### Basic implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186948c4",
   "metadata": {},
   "source": [
    "We implement a custom convolution layer. Note that the layer we are creating is not trainable (which I've done to make the implementation of convolution a bit easier to understand), but it doesn't take too much effort to make the `DIYConv2D` layer usable. \n",
    "In addition to the this convolution layer, I've also created a `test_conv_impl` to compare our convolutional layer with the one created by Pytorch. The code below implements the convolution (cross-correlation) operation that we discussed above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49cf931-90e6-4a87-b288-cebef618f356",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DIYConv2D(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, padding='valid', stride=1):\n",
    "        # TODO: implement padding and stride\n",
    "        super().__init__()\n",
    "        self.out_channels = out_channels\n",
    "        self.in_channels = in_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.kernel = torch.rand(out_channels, in_channels, kernel_size, kernel_size)\n",
    "        self.bias = torch.rand(out_channels,)\n",
    "\n",
    "    # For testing\n",
    "    def _set_parameters(self, kernel, bias):\n",
    "        self.kernel = kernel\n",
    "        self.bias = bias\n",
    "        assert self.kernel.shape == (self.out_channels, self.in_channels, self.kernel_size, self.kernel_size)\n",
    "        assert self.bias.shape == (self.out_channels,)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        height = x.shape[1] - self.kernel_size + 1\n",
    "        width = x.shape[2] - self.kernel_size + 1\n",
    "        conv = torch.zeros((self.out_channels, height, width))\n",
    "        for i in range(self.out_channels):\n",
    "            for j in range(height):\n",
    "                for k in range(width):\n",
    "                    conv[i][j][k] = torch.sum(self.kernel[i, ...] * x[..., j:j+self.kernel_size, k:k+self.kernel_size])\n",
    "        return conv + self.bias.reshape(self.out_channels, 1, 1)\n",
    "\n",
    "def test_conv_impl(img_width, img_height, kernel_size, padding=0, stride=1):\n",
    "    img = torch.rand(1, img_width, img_height)\n",
    "    conv_layer = nn.Conv2d(kernel_size=kernel_size, in_channels=1, out_channels=3, stride=stride, padding=padding, dilation=1, bias=True)\n",
    "    diy_conv_layer = DIYConv2D(1, 3, kernel_size=kernel_size, padding=padding, stride=stride)\n",
    "    diy_conv_layer._set_parameters(conv_layer.weight, conv_layer.bias)\n",
    "    conv_layer_output = conv_layer(img)\n",
    "    diy_conv_layer_output = diy_conv_layer(img)\n",
    "    print(conv_layer_output)\n",
    "    print(diy_conv_layer_output)\n",
    "    assert torch.allclose(conv_layer_output, diy_conv_layer_output, atol=1e-5, rtol=1e-5)\n",
    "\n",
    "test_conv_impl(3, 3, 2)\n",
    "test_conv_impl(28, 28, 3)\n",
    "test_conv_impl(32, 64, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f56f8ec8-1508-40f9-a227-884affebb227",
   "metadata": {},
   "source": [
    "#### Padding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6b53c9",
   "metadata": {},
   "source": [
    "One problem with the convolution operation is that pixels near the edge of the image are not convolved. We can solve this problem by adding *padding* to the image. Another reason to use padding is to ensure that the dimensions of the feature map match the dimensions of the input. Consider the following $3 \\times 3$ image:\n",
    "\n",
    "$\\begin{bmatrix} 1 & 2 & 3 \\\\ 4 & 5 & 6 \\\\ 7 & 8 & 9 \\end{bmatrix}$\n",
    "\n",
    "And say we apply one layer of padding. Then, the image becomes: \n",
    "\n",
    "$\\begin{bmatrix} 0 & 0 & 0 & 0 & 0 \\\\ 0 & 1 & 2 & 3 & 0 \\\\ 0 & 4 & 5 & 6 & 0 \\\\ 0 & 7 & 8 & 9 & 0 \\\\  0 & 0 & 0 & 0 & 0 \\end{bmatrix}$\n",
    "\n",
    "If we were to now apply a $2 \\times 2$ kernel, we would be able to convolve the corners and edges of the image. In general, if we add $P$ pixels on each side of a $J \\times K$ image and convolve it with a $M \\times M$ kernel, then the dimension of the feature map is $(J + 2P - M + 1) \\times (K + 2P - M + 1)$. When $P = 0$, we say the feature map has \"valid\" padding and when $P$ is selected to make the feature map have the same dimensions as the input, we say it has \"same\" padding. For odd $M$, we can select $P = \\frac{M-1}{2}$. Then, the $(J + 2P - M + 1) \\times (K + 2P - M + 1)$ image will be $J \\times K$ in size, the same as the original image.\n",
    "\n",
    "> Note: Adding padding to images for even-sized kernels is not necessarily well-defined. It seems that Pytorch will do this by adding padding to the right and bottom of the matrix as described [here](https://github.com/pytorch/pytorch/issues/3867). Generally for computer vision tasks, we use odd-sized kernels so that the padding is symmetric on all sides and there is a well-defined central pixel (see the textbook by Bishop in the References below for more details)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4957416-bb1c-46fd-9f7f-0f9fa7a2e8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DIYConv2D(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, padding='valid', stride=1):\n",
    "        super().__init__()\n",
    "        self.out_channels = out_channels\n",
    "        self.in_channels = in_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.kernel = torch.rand(out_channels, in_channels, kernel_size, kernel_size)\n",
    "        self.bias = torch.rand(out_channels,)\n",
    "        self.padding = padding\n",
    "\n",
    "    # For testing\n",
    "    def _set_parameters(self, kernel, bias):\n",
    "        self.kernel = kernel\n",
    "        self.bias = bias\n",
    "        assert self.kernel.shape == (self.out_channels, self.in_channels, self.kernel_size, self.kernel_size)\n",
    "        assert self.bias.shape == (self.out_channels,)\n",
    "\n",
    "    def _add_padding(self, x):\n",
    "        padding = None\n",
    "        if self.padding == 'valid':\n",
    "            padding = 0\n",
    "        elif self.padding == 'same':\n",
    "            padding = (self.kernel_size - 1) // 2\n",
    "        elif isinstance(self.padding, int):\n",
    "            padding = self.padding\n",
    "        else:\n",
    "            raise Exception(f'Undefined padding mode \\\"{self.padding}\\\"')\n",
    "        padded_x = x\n",
    "        for _ in range(padding):\n",
    "            padding_vertical = torch.zeros((padded_x.shape[0], padded_x.shape[1] + 2, 1))\n",
    "            padding_horizontal = torch.zeros((padded_x.shape[0], 1, padded_x.shape[2]))\n",
    "            padded_x = torch.cat((padding_horizontal, padded_x, padding_horizontal), dim=1)\n",
    "            padded_x = torch.cat((padding_vertical, padded_x, padding_vertical), dim=2)\n",
    "        return padded_x\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self._add_padding(x)\n",
    "        height = x.shape[1] - self.kernel_size + 1\n",
    "        width = x.shape[2] - self.kernel_size + 1\n",
    "        conv = torch.zeros((self.out_channels, height, width))\n",
    "        for i in range(self.out_channels):\n",
    "            for j in range(height):\n",
    "                for k in range(width):\n",
    "                    conv[i][j][k] = torch.sum(self.kernel[i, ...] * x[..., j:j+self.kernel_size, k:k+self.kernel_size])\n",
    "        return conv + self.bias.reshape(self.out_channels, 1, 1)\n",
    "\n",
    "test_conv_impl(3, 3, 3, padding='valid')\n",
    "test_conv_impl(3, 3, 3, padding='same')\n",
    "test_conv_impl(3, 3, 1, padding=2)\n",
    "test_conv_impl(28, 28, 5, padding='valid')\n",
    "test_conv_impl(28, 28, 5, padding='same')\n",
    "test_conv_impl(28, 28, 5, padding=2)\n",
    "test_conv_impl(32, 64, 7, padding='valid')\n",
    "test_conv_impl(32, 64, 7, padding='same')\n",
    "test_conv_impl(32, 64, 7, padding=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13b316b-5b24-4839-89ae-a05eab9568f3",
   "metadata": {},
   "source": [
    "#### Stride"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c6a9b78",
   "metadata": {},
   "source": [
    "Sometimes, instead of padding, we wish to make the feature map smaller than the input rather than keep it of a similar size. We can do this by using a different *stride* when applying the kernel. Essentially, instead of moving the sliding window over by $1$ each time, we skip $S$ pixels. The resulting feature map has the size $(\\lfloor \\frac{J + 2P - M}{S} + 1 \\rfloor) \\times (\\lfloor \\frac{K + 2P - M}{S} + 1 \\rfloor)$. The code below is not too different from the above; we just skip $S$ pixels in the loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e9d224-8138-41ec-97ed-081ab415a39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DIYConv2D(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, padding='valid', stride=1):\n",
    "        super().__init__()\n",
    "        self.out_channels = out_channels\n",
    "        self.in_channels = in_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.kernel = torch.rand(out_channels, in_channels, kernel_size, kernel_size)\n",
    "        self.bias = torch.rand(out_channels)\n",
    "        self.padding = padding\n",
    "        self.stride = stride\n",
    "\n",
    "    # For testing\n",
    "    def _set_parameters(self, kernel, bias):\n",
    "        self.kernel = kernel\n",
    "        self.bias = bias\n",
    "        assert self.kernel.shape == (self.out_channels, self.in_channels, self.kernel_size, self.kernel_size)\n",
    "        assert self.bias.shape == (self.out_channels,)\n",
    "\n",
    "    def _add_padding(self, x):\n",
    "        padding = None\n",
    "        if self.padding == 'valid':\n",
    "            padding = 0\n",
    "        elif self.padding == 'same':\n",
    "            padding = (self.kernel_size - 1) // 2\n",
    "        elif isinstance(self.padding, int):\n",
    "            padding = self.padding\n",
    "        else:\n",
    "            raise Exception(f'Undefined padding mode \\\"{self.padding}\\\"')\n",
    "        padded_x = x\n",
    "        for _ in range(padding):\n",
    "            padding_vertical = torch.zeros((padded_x.shape[0], padded_x.shape[1] + 2, 1))\n",
    "            padding_horizontal = torch.zeros((padded_x.shape[0], 1, padded_x.shape[2]))\n",
    "            padded_x = torch.cat((padding_horizontal, padded_x, padding_horizontal), dim=1)\n",
    "            padded_x = torch.cat((padding_vertical, padded_x, padding_vertical), dim=2)\n",
    "        return padded_x\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self._add_padding(x)\n",
    "        height = int(np.floor(1 + (x.shape[1] - self.kernel_size) / self.stride))\n",
    "        width = int(np.floor(1 + (x.shape[2] - self.kernel_size) / self.stride))\n",
    "        conv = torch.zeros((self.out_channels, height, width))\n",
    "        jc, kc = 0, 0\n",
    "        for i in range(self.out_channels):\n",
    "            jc = 0\n",
    "            for j in range(0, x.shape[1] - self.kernel_size + 1, self.stride):\n",
    "                kc = 0\n",
    "                for k in range(0, x.shape[2] - self.kernel_size + 1, self.stride):\n",
    "                    conv[i][jc][kc] = torch.sum(self.kernel[i, ...] * x[..., j:j+self.kernel_size, k:k+self.kernel_size])\n",
    "                    kc += 1\n",
    "                jc += 1\n",
    "        return conv + self.bias.reshape(self.out_channels, 1, 1)\n",
    "\n",
    "test_conv_impl(3, 3, 3, padding='valid')\n",
    "test_conv_impl(3, 3, 3, padding='same')\n",
    "test_conv_impl(3, 3, 1, padding=2)\n",
    "test_conv_impl(28, 28, 5, padding='valid', stride=2)\n",
    "test_conv_impl(28, 28, 5, padding='same')\n",
    "test_conv_impl(28, 28, 5, padding=2, stride=3)\n",
    "test_conv_impl(32, 64, 7, padding='valid', stride=2)\n",
    "test_conv_impl(32, 64, 7, padding='same')\n",
    "test_conv_impl(32, 64, 7, padding=10, stride=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aaab094-8153-4b92-984c-467b63945e82",
   "metadata": {},
   "source": [
    "#### Pooling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c618979-cb1f-4927-87ed-284edea3afee",
   "metadata": {},
   "source": [
    "This next aspect is separate from the convolution operation we have been writing. *Pooling* is essentially the convolution operation except instead of multiplying and summing with a kernel, we apply some other function. The two most common types of pooling are average pooling and max pooling. To illustrate what pooling is, we perform a $2 \\times 2$ max pool operation on the following $3 \\times 3$ matrix:\n",
    "\n",
    "$\\begin{bmatrix} 1 & 2 & 3 \\\\ 4 & 5 & 6 \\\\ 7 & 8 & 9 \\end{bmatrix}$\n",
    "\n",
    "The pooling operation is still like a sliding window, so we look at the first $2 \\times 2$ submatrix:\n",
    "\n",
    "$\\begin{bmatrix} 1 & 2 \\\\ 4 & 5 \\end{bmatrix}$\n",
    "\n",
    "and we take the maximum of all these elements, which is $5$. We then slide the window over and take the maximum of the next $2 \\times 2$ submatrix:\n",
    "\n",
    "$\\begin{bmatrix} 2 & 3 \\\\ 5 & 6 \\end{bmatrix}$\n",
    "\n",
    "which is $6$. Continuing this way, we arrive at the following max-pooled matrix:\n",
    "\n",
    "\\begin{bmatrix} 5 & 6 \\\\ 8 & 9 \\end{bmatrix}\n",
    "\n",
    "If we were to use average pooling, we would take the average of each window and use that as the entries to get the following matrix:\n",
    "\n",
    "\\begin{bmatrix} 3 & 4 \\\\ 6 & 7 \\end{bmatrix}\n",
    "\n",
    "The primary use of the pooling operation is to allow for *invariance*. For example, in the case of the FashionMNIST dataset, we would like our neural network to be invariant to translations and rotations of the images, i.e, it should be able to tell that a T-shirt is a T-shirt regardless of whether the image is upside-down or rightside-up. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a9a97e5-57ae-4108-85a5-8ae55847130b",
   "metadata": {},
   "source": [
    "#### Training and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95187ee",
   "metadata": {},
   "source": [
    "Now all that's left to do is train the network. The network below is a modified version of the LeNet5 network implemented in this Pytorch tutorial. It embodies many of the principles that we discussed above for a convolutional network. It uses max-pooling to be invariant to transformations and increases the number of filters to magnify the receptive field of earlier layers. \n",
    "The convolution-ReLU-maxpool trend is typical for most convolutional neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13beb66f-6aa9-4d86-a311-9a6006f2d85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FashionClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 4 * 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716e2e36-01da-4ca4-893a-a6cd76e29cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "classifier = FashionClassifier()\n",
    "classifier.train(True)\n",
    "summary(classifier, input_size=(batch_size, 1, 28, 28))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a068ee7b",
   "metadata": {},
   "source": [
    "Since this is an image classification task, we use cross-entropy loss:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6618f7c-ffda-4e91-b067-d743dcf00a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(classifier.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607bd70b-a13e-4cdf-ad37-0b8de0534a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    print(f'Epoch {epoch+1}:')\n",
    "    total_epoch_loss = 0\n",
    "    i = 0\n",
    "    for input, target in DataLoader(train_dataset, batch_size=batch_size, shuffle=True):\n",
    "        x = input.cuda()\n",
    "        y = target.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        yhat = classifier(x)\n",
    "        loss = loss_fn(yhat, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_epoch_loss += loss.item()\n",
    "        # 1875 / 375 = 5, so 5 reports per epoch\n",
    "        if i % 375 == 374:\n",
    "            print(f' batch {i+1} loss: {total_epoch_loss / 1000}')\n",
    "            total_epoch_loss = 0\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c8e821-6e73-43c4-8ae2-0323c64a4832",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = 0.\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(test_dataset):\n",
    "        x, y = data\n",
    "        yhat = classifier(x.cuda())\n",
    "        accuracy += torch.argmax(yhat) == y\n",
    "accuracy / len(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a006d1b",
   "metadata": {},
   "source": [
    "If you run this in the notebook, then you should get roughly 85% accuracy on the dataset, which is not bad for a small network. Though this article explored convolutions for a simple image classification task, the convolution operation can be used for object detection, face recognition, and non-computer-vision tasks, such as audio/speech processing (in this case, the convolution would be one dimensional). Either way, the main reason to use convolutions in a network boils down to 1) parameter sharing, 2) sparse connections, and 3) for inference on images of different sizes without retraining."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "072f76a0-c967-449e-b97f-4cb71e38bc6e",
   "metadata": {},
   "source": [
    "### References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ebb2a25-0f0d-449d-b2c3-d95a4b1e2eae",
   "metadata": {},
   "source": [
    "* Modified LeNet5 network: https://pytorch.org/tutorials/beginner/introyt/trainingyt.html\n",
    "* Pytorch tutorial for basic neural network training: https://pytorch.org/tutorials/beginner/basics/data_tutorial.html\n",
    "* FashionMNIST dataset: https://github.com/zalandoresearch/fashion-mnist\n",
    "* Issue discussing padding for even-sized kernels: https://github.com/pytorch/pytorch/issues/3867\n",
    "* Deep Learning: Foundations and Concepts: https://www.bishopbook.com/\n",
    "* Cross Correlation operation: https://en.wikipedia.org/wiki/Cross-correlation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlt",
   "language": "python",
   "name": "dlt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
